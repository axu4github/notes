# 《Spark 快速大数据分析》读书笔记

## 第3章 RDD 编程

### 3.1 RDD 基础

> **在任何时候都可以进行重算是我们为什么把 `RDD` 描述为 `弹性` 的原因。** 当保存 `RDD` 数据的一台机器失败时， `Spark` 还可以以这种特性来重算出已经丢失的分区，这一过程对用户是完全透明的。
/.
- `Spark` 的 `RDD` 是一个 不可变的分布式对象集合。
- 每个 `RDD` 有多个分区，这些分区分布在集群中的不同节点上。
- `RDD` 有两种类型的操作： `Transformation` 和 `Action` 。
- `Transformation` 操作会把一个 `RDD` 转化成为一个新的 `RDD` 。
- `Action` 操作会通过 `RDD` 计算出一个结果，返回给 `Driver` 或者 把结构存储到外部的存储系统中。


### 3.2 创建 RDD

> 创建 `RDD` 有两种方法。

##### 读取外部数据集

```python
# 读取外部数据集创建 RDD
>>> lines = sc.textFile("/path/to/README.md")
```

##### 调用 parallelize() 函数

```python
# 调用 parallelize() 函数创建 RDD
>>> lines = sc.parallelize(["pandas", "i like pandas"])
```
